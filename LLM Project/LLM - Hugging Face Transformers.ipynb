{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f86067f-b3f8-4fe7-a4ff-83811830b507",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae7b8e39-7a9e-4b03-b0ff-1c8455cae803",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "model_path = r'C:\\Users\\1852267\\OneDrive - TCS COM PROD\\Desktop\\AI Engineer Course\\NLP Section\\hugging_face\\models\\sentiment_model'\n",
    "sentiment_classifier = pipeline('sentiment-analysis', model = model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "10d992ba-a381-4968-9cd3-5d17428a91eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9997805953025818}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_classifier(\"yes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a222f245-40a8-4dac-bdc7-4d8956e6cf4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [101, 1045, 1005, 1049, 2061, 7568, 2000, 2022, 4083, 2055, 2312, 2653, 4275, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(r'C:\\Users\\1852267\\OneDrive - TCS COM PROD\\Desktop\\AI Engineer Course\\Hugging Face Models\\google-bert.bert-base-uncased')\n",
    "sentence = \"I'm so excited to be learning about large language models\"\n",
    "input_ids = tokenizer(sentence)\n",
    "print(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e2abe01-c11e-439d-96ad-c79f01e45004",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenizer.tokenize(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6404af91-0c7c-4dd5-aff4-818fad677851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', \"'\", 'm', 'so', 'excited', 'to', 'be', 'learning', 'about', 'large', 'language', 'models']\n"
     ]
    }
   ],
   "source": [
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "001a5310-9d9e-47a3-91e0-6b04fbb81997",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS]'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0014b30d-df7a-4ac0-9a52-dac7b1235c70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[SEP]'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(102)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ceff56fd-66c7-452a-ad2c-c8958e60ec98",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_ids = tokenizer.convert_tokens_to_ids(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "605e88f3-6d22-4a13-a9b6-fabebdacf98e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1045, 1005, 1049, 2061, 7568, 2000, 2022, 4083, 2055, 2312, 2653, 4275]\n"
     ]
    }
   ],
   "source": [
    "print(tokens_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8341208e-9dfc-46f3-a812-e2a03b1f4056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', \"'\", 'm', 'so', 'excited', 'to', 'be', 'learning', 'about', 'large', 'language', 'models']\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.convert_ids_to_tokens(tokens_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8743f40e-fa3a-4e9e-9088-cd0b1bf65ade",
   "metadata": {},
   "source": [
    "# Hugging Face and PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b03aa1f9-01cb-457b-8c7f-73ecddbecef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm so excited to be learning about large language models\n",
      "{'input_ids': tensor([[ 101, 1045, 1005, 1049, 2061, 7568, 2000, 2022, 4083, 2055, 2312, 2653,\n",
      "         4275,  102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'POSITIVE'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "\n",
    "tokenizer_2 = AutoTokenizer.from_pretrained(r\"C:\\Users\\1852267\\OneDrive - TCS COM PROD\\Desktop\\AI Engineer Course\\Hugging Face Models\\distilbert\")\n",
    "input_ids_2 = tokenizer_2(sentence, return_tensors='pt')\n",
    "print(sentence)\n",
    "print(input_ids_2)\n",
    "print('\\n')\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(r'C:\\Users\\1852267\\OneDrive - TCS COM PROD\\Desktop\\AI Engineer Course\\Hugging Face Models\\distilbert')\n",
    "with torch.no_grad():\n",
    "    logits = model(**input_ids_2).logits\n",
    "\n",
    "predicted_class_id = logits.argmax().item()\n",
    "model.config.id2label[predicted_class_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7afd53f-1fe5-4831-8d54-a4113c9fec40",
   "metadata": {},
   "source": [
    "# Saving and loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "747e97d3-1c84-4228-af63-bf28ff00281d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_directory = 'trained_model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4e512e06-caac-4642-a327-ad72a34d6d5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('trained_model\\\\tokenizer_config.json',\n",
       " 'trained_model\\\\special_tokens_map.json',\n",
       " 'trained_model\\\\vocab.txt',\n",
       " 'trained_model\\\\added_tokens.json',\n",
       " 'trained_model\\\\tokenizer.json')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_2.save_pretrained(model_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b1adabaf-b2a0-413a-b6b7-70ed0475d1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(model_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f5ffc1-03f3-4db6-b9c9-a9da63f8dedf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (llms_course_env)",
   "language": "python",
   "name": "llms_course_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
